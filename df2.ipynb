{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from scipy.stats import binomtest, chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"df2.xlsx\", usecols=\"A:B\", skiprows=1)\n",
    "criteria = pd.read_excel(\"df2.xlsx\", usecols=\"D:F\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Điểm\": \"Score\", \"Good=0/Bad=1\": \"Label\"}, inplace=True)\n",
    "criteria.rename(columns={\"Master Scale\": \"Scale\", \"Điểm.1\": \"Criteria\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Score']]\n",
    "y = df['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42)\n",
    "}\n",
    "param_grids = {\n",
    "    \"Random Forest\": {'n_estimators': [50, 100], 'max_depth': [5, None]},\n",
    "    \"Gradient Boosting\": {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]},\n",
    "    \"Decision Tree\": {'max_depth': [5, None]},\n",
    "    \"Logistic Regression\": {'C': [0.01, 0.1, 1.0]}\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in models.items():\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=5, scoring='roc_auc')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = (grid.best_estimator_, grid.best_params_, grid.best_score_)\n",
    "    gini = 2 * grid.best_score_ - 1\n",
    "    print(f\"{name}: {grid.best_params_}, ROC AUC: {grid.best_score_:.4f}, Gini: {gini:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_boost = {\n",
    "    \"XGBoost\": {\"n_estimators\": [50, 100], \"max_depth\": [3, 5], \"learning_rate\": [0.01, 0.1]},\n",
    "    \"LightGBM\": {\"n_estimators\": [20, 50], \"max_depth\": [3, 5], \"learning_rate\": [0.01, 0.1]}\n",
    "}\n",
    "\n",
    "models.update({\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "})\n",
    "\n",
    "for name in [\"XGBoost\", \"LightGBM\"]:\n",
    "    grid = GridSearchCV(models[name], param_boost[name], cv=5, scoring='roc_auc')\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[name] = (grid.best_estimator_, grid.best_params_, grid.best_score_)\n",
    "    print(f\"{name} Best Params: {grid.best_params_}, ROC AUC: {grid.best_score_:.4f}, Gini: {2*grid.best_score_-1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, (estimator, _, _) in best_models.items():\n",
    "    y_proba = estimator.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves by Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(best_models)\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    [[k, v[2], 2*v[2] - 1] for k, v in best_models.items()],\n",
    "    columns=['model_name', 'ROC', 'gini']\n",
    ")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hosmer_lemeshow_test(y_true, y_pred, n_groups=10):\n",
    "    \"\"\"\n",
    "    Perform Hosmer-Lemeshow test\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (array): Actual binary outcomes\n",
    "    y_pred (array): Predicted probabilities\n",
    "    n_groups (int): Number of groups for the test\n",
    "    \"\"\"\n",
    "    # Sort predictions and create groups\n",
    "    indices = np.argsort(y_pred)\n",
    "    y_true = y_true[indices]\n",
    "    y_pred = y_pred[indices]\n",
    "    \n",
    "    # Create groups\n",
    "    size = len(y_true) // n_groups\n",
    "    groups = [y_true[i:i + size] for i in range(0, len(y_true), size)]\n",
    "    pred_groups = [y_pred[i:i + size] for i in range(0, len(y_pred), size)]\n",
    "    \n",
    "    # Calculate observed and expected frequencies\n",
    "    observed = np.array([sum(group) for group in groups])\n",
    "    expected = np.array([sum(pred_group) for pred_group in pred_groups])\n",
    "    \n",
    "    # Calculate chi-square statistic\n",
    "    chi_square = np.sum((observed - expected) ** 2 / (expected * (1 - expected/size)))\n",
    "    \n",
    "    # Calculate p-value (df = n_groups - 2)\n",
    "    p_value = 1 - chi2.cdf(chi_square, n_groups - 2)\n",
    "    return chi_square, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Observed Successes: 139\n",
      "Expected Successes (Model): 133.16\n",
      "Binomial Test p-value: 0.5794\n",
      "Gradient Boosting:\n",
      "Observed Successes: 139\n",
      "Expected Successes (Model): 134.24\n",
      "Binomial Test p-value: 0.6454\n",
      "Decision Tree:\n",
      "Observed Successes: 139\n",
      "Expected Successes (Model): 133.63\n",
      "Binomial Test p-value: 0.6119\n",
      "Logistic Regression:\n",
      "Observed Successes: 139\n",
      "Expected Successes (Model): 135.23\n",
      "Binomial Test p-value: 0.7136\n",
      "XGBoost:\n",
      "Observed Successes: 139\n",
      "Expected Successes (Model): 131.66\n",
      "Binomial Test p-value: 0.4863\n",
      "LightGBM:\n",
      "Observed Successes: 139\n",
      "Expected Successes (Model): 132.36\n",
      "Binomial Test p-value: 0.5470\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binomtest\n",
    "import numpy as np\n",
    "\n",
    "for model in best_models:\n",
    "    y_proba = best_models[model][0].predict_proba(X_test)[:, 1]  # Predicted probabilities\n",
    "    mean_predicted_prob = np.mean(y_proba)  # Average predicted probability\n",
    "    expected_successes = sum(y_proba)  # Sum of predicted probabilities\n",
    "\n",
    "    # Binomial test\n",
    "    observed_successes = sum(y_test)\n",
    "    num_trials = len(y_test)\n",
    "    binom_pvalue = binomtest(observed_successes, num_trials, mean_predicted_prob).pvalue\n",
    "\n",
    "    print(f\"{model}:\")\n",
    "    print(f\"Observed Successes: {observed_successes}\")\n",
    "    print(f\"Expected Successes (Model): {expected_successes:.2f}\")\n",
    "    print(f\"Binomial Test p-value: {binom_pvalue:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Binomial Test 2 tails : 0.5794\n",
      "Binomial Test 1 tail : 0.3079\n",
      "Hosmer-Lemeshow Test: (156.74741107520205, 0.0)\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "Binomial Test 2 tails : 0.6454\n",
      "Binomial Test 1 tail : 0.3438\n",
      "Hosmer-Lemeshow Test: (10.378005419429426, 0.23949052509886692)\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "Binomial Test 2 tails : 0.6119\n",
      "Binomial Test 1 tail : 0.3235\n",
      "Hosmer-Lemeshow Test: (nan, nan)\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "Binomial Test 2 tails : 0.7136\n",
      "Binomial Test 1 tail : 0.3781\n",
      "Hosmer-Lemeshow Test: (14.59487953989061, 0.06751826810686656)\n",
      "\n",
      "\n",
      "XGBoost:\n",
      "Binomial Test 2 tails : 0.4863\n",
      "Binomial Test 1 tail : 0.2604\n",
      "Hosmer-Lemeshow Test: (13.552937103869457, 0.09418822527710602)\n",
      "\n",
      "\n",
      "LightGBM:\n",
      "Binomial Test 2 tails : 0.5470\n",
      "Binomial Test 1 tail : 0.2821\n",
      "Hosmer-Lemeshow Test: (10.323475819071094, 0.24305209490981683)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nk/6_ymhlt94l97ghl62d13wtym0000gn/T/ipykernel_54758/669386921.py:25: RuntimeWarning: divide by zero encountered in divide\n",
      "  chi_square = np.sum((observed - expected) ** 2 / (expected * (1 - expected/size)))\n",
      "/var/folders/nk/6_ymhlt94l97ghl62d13wtym0000gn/T/ipykernel_54758/669386921.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  chi_square = np.sum((observed - expected) ** 2 / (expected * (1 - expected/size)))\n"
     ]
    }
   ],
   "source": [
    "for model in best_models:\n",
    "    y_proba = best_models[model][0].predict_proba(X_test)[:, 1]  \n",
    "    mean_predicted_prob = np.mean(y_proba)  # Average predicted probability\n",
    "    expected_successes = sum(y_proba)  # Sum of predicted probabilities\n",
    "    observed_successes = sum(y_test)\n",
    "    num_trials = len(y_test)\n",
    "    \n",
    "    print(f\"{model}:\")\n",
    "    print(f'Binomial Test 2 tails : {binomtest(observed_successes, num_trials, mean_predicted_prob, alternative=\"two-sided\").pvalue:.4f}')\n",
    "    print(f'Binomial Test 1 tail : {binomtest(observed_successes, num_trials, mean_predicted_prob, alternative=\"greater\").pvalue:.4f}')\n",
    "    print(f\"Hosmer-Lemeshow Test: {hosmer_lemeshow_test(y_test.values, y_proba)}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criterias for classification model\n",
    "\n",
    "## AUC, ROC\n",
    "TPR = TP / (TP + FN) tỉ lệ dương thật\n",
    "FPR = FP / (FP + TN) tỉ lê lỗi dương giả\n",
    "\n",
    "ROC tạo ra bằng cách thay đổi threshold của mô hình đối với prediction, khi giảm threshold, TPR tăng, FPR cũng tăng, và ngược lại\n",
    "\n",
    "Đọc ROC:\n",
    "- Đường cong của mô hình là hiệu suất dự đoán của mô hình, càng gần trục Y (TPR) thì mô hình dự đoán càng tốt\n",
    "- Đường chéo là việc dự đoán ngẫu nhiên ban đầu\n",
    "\n",
    "AUC: diện tích dưới đường ROC, càng lớn thì mô hình càng tốt, được tính từ TPR và FPR. AUC = 1 thì mô hình hoàn hảo, AUC = 0.5 thì mô hình dự đoán ngẫu nhiên\n",
    "\n",
    "## Gini\n",
    "Gini đo lường khả năng phân biệt giữa 2 lớp, là việc chuyển đổi AUC để dễ dàng so sánh\n",
    "Gini = 2 * AUC - 1, càng lớn thì mô hình càng tốt, Gini = 1 thì mô hình hoàn hảo, Gini = 0 thì mô hình dự đoán ngẫu nhiên\n",
    "\n",
    "Tuy nhiên, chúng ta không nên để ROC, Gini = 1, gây ra overfit mô hình, nên cần phải cân bằng giữa precision và recall (tuỳ trường hợp lựa chọn criteria theo thực tế)\n",
    "\n",
    "## Binomial test \n",
    "Kiểm tra xem mô hình có tốt hơn tỉ lệ cụ thể nào không, ta có hypothesis sau:\n",
    "- H0: mô hình không tốt hơn tỉ lệ cụ thể (1 tail : p > p0) (2 tails : p != p0)\n",
    "- H1: mô hình tốt hơn tỉ lệ cụ thể (1 tail : p < p0) (2 tails : p > p0)\n",
    "\n",
    "## Hosmer-Lemeshow Test\n",
    "Là kiểm định đánh giá mức độ phù hợp của mô hình logistic regression ( có thể áp dụng cho bài toán classification khác nếu có lớp cuối là logits, biến phụ thuộc nhị phân, phân nhóm dựa trên xác suất).\n",
    "- H0: mô hình hiệu chỉnh tốt, không có sự khác biệt đáng kể giữa các xác suất quan sát và kì vọng\n",
    "- H1: mô hình hiệu chỉnh không tốt, có sự khác biệt đáng kể giữa các xác suất quan sát và kì vọng "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
